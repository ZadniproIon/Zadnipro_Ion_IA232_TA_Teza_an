L2T-DLN: Learning to Teach with Dynamic Loss Network

By Zhoyang Hai and Liyuan Pan and Xiabi Liu and Zhengzheng Liu and Mirna Yunita

Abstract

With the concept of teaching being introduced to the machine learning community, a teacher model start using dynamic loss functions to teach the training of a student model. The dynamic intends to set adaptive loss functions to different phases of student model learning. In existing works, the teacher model 1) merely determines the loss function based on the present states of the student model, i.e. , disregards the experience of the teacher; 2) only utilizes the states of the student model, e.g. , training iteration number and loss/accuracy from training/validation sets, while ignoring the states of the loss function. In this paper, we first formulate the loss adjustment as a temporal task by designing a teacher model with memory units, and, therefore, enables the student learning to be guided by the experience of the teacher model. Then, with a dynamic loss network, we can additionally use the states of the loss to assist the teacher learning in enhancing the interactions between the teacher and the student model. Extensive experiments demonstrate our approach can enhance student learning and improve the performance of various deep models on real-world tasks, including classification, objective detection, and semantic segmentation scenarios.

1 Introduction

The art of instruction, a critical component in the ongoing evolution of contemporary human civilization, serves to equip students with the necessary knowledge and abilities. In the intricate tapestry of human society, the proliferation of educated individuals is not solely contingent upon their innate abilities to absorb information, but rather, it is significantly indebted to the wisdom and guidance bestowed by their instructors. The roles and responsibilities of educators span a broad horizon: delineating the parameters of instruction (such as the subjects and competencies that students are expected to master by the conclusion of a course), selecting appropriate learning resources (including textbooks), and evaluating the progress of students (through various assignments or assessments). An effective pedagogy entails the continuous and adaptive fine-tuning of teaching methods, informed by self-analysis and student feedback.

In L2T, a teacher model uses a dynamic loss function, which acts as an exam paper, to train and optimize the student model (as shown in Figure 1 (a)). However, existing approaches adjust the loss functions by only employing a simple feedforward network as the teacher model, and neglecting the temporal nature of loss function adjustment. The disregarding of the experience accumulation for teachers ( e.g. , the ability to analyze all previous exam scores for a student), and, therefore, limits the potential of L2T. In addition, in previous works, the teacher model only focuses on the state of the student model, i.e. , training iteration number Wu et al. [2018] , training/validation accuracy Wu et al. [2018] , training/validation loss Baik et al. [2021] , and the output of the student model Huang et al. [2019] . However, the states of loss functions ( e.g. , the gradients concerning loss functions) are neglected, which dilutes the benefit of improving the exam paper. In other words, the teacher needs to consider that the question changes of an exam paper also influence the performance of a student.

In this paper, we propose an L2T framework with a Dynamic Loss Network (L2T-DLN), to address the above-mentioned issue (in Figure 1 (b)). First, we adopt a Long-Short Term Memory (LSTM) model as the teacher and design a differentiable three-stage asynchronous optimization strategy. Then, to ensure the teacher model can be optimized with the state of loss functions, we design a Dynamic Loss Network (DLN) instead of using the dynamic loss function (DLF). Specifically, we start by optimizing the student model through backpropagation in the first step with a fixed DLN as the loss function. Then, compute the gradient of the validation error of the student model with respect to the DLN. Next, we input this gradient into the teacher model, and the output of the teacher model is used to update the DLN. To achieve the updating of the teacher model, we perform another round of student learning with the updated DLN and obtain the gradient of the validation error of the updated student with respect to the teacher model. Moreover, we analyze how L2T-DLN exploits the negative curvature by using a special alternating gradient descent (AGD) sequence, achieving a differentiable asynchronous optimization.

In summary, the usage of the gradient concerning DLN and the LSTM teacher model both ensure the teacher model captures and maintains short- and long-term temporal information, which can further improve the performance of loss function teaching, compared to feedforward teachers Wu et al. [2018] .

Our main contributions are 1) design a dynamic loss network-based teaching strategy to let the teacher model learn optimized by the gradient of DLN; 2) use LSTM as the teacher model to update the DLN with the temporal information of the teacher model; and 3) a convergence analysis of the approach, which is treated as a special AGD sequence and has the potential to escape strict saddle points. We conduct extensive experiments on a wide range of loss functions and tasks to demonstrate the effectiveness of our approach.

2 Related work


In the realm of contemporary artificial intelligence (AI), the innovative approach termed Learning to Teach (L2T) [13] provides a robust and encompassing perspective on AI instruction. This encompasses the processes of training data teaching, loss function teaching, and hypothesis space teaching. Notably, L2T discards a longstanding presumption prevalent in prior machine teaching literature [59], which assumes the existence of an ideal, pre-existing student model. Our research aligns with the overarching L2T framework, concentrating on the intricate terrain of loss function teaching. This includes a meticulous examination of the problem's setup and the development of efficient strategies for dynamically adjusting loss functions during the training of machine learning models.

During the training of a student model, there is a variation in the distribution of predictions where earlier in the training the distribution tends to differ from that at convergence. Consequently, an adaptive loss function is crucial. Existing works Wu et al. [2018] formulate the loss adjustment as some independent tasks by performing a multi-layer perceptron (MLP) as the teacher model. The differences lie in the representation of dynamic loss functions and the input information of teacher models. The representation of the dynamic loss function includes the variation of handcrafted loss functions Wu et al. [2018] and neural network Huang et al. [2019] . The input information contains the training iteration number Wu et al. [2018] , training/validation accuracy Wu et al. [2018] , training/validation loss Baik et al. [2021] , and the output of the student model Huang et al. [2019] . In detail, Wu et al. [2018] trains a neural network with an attention mechanism to generate a coefficient matrix between the prediction of the student and the ground truth. Huang et al. [2019] constructs the teaching-learning framework with reinforcement learning. Their teacher also employs an MLP and generates the policy gradient for a loss network. Liu and Lai [2020] utilizes a teacher model to guide the selection and combination of handcrafted loss functions. Baik et al. [2021] performs a teacher to generate two weights for each layer of a loss network, and then updates the parameters of the loss network by affine transformation with the two weights.

In our proposed learning framework, a teacher model is employed to generate loss functions for a student model, which is the daily machine learning model designed to perform a given task. The teacher model is structured based on human teaching principles, with a focus on adaptability and self-improvement. First, the loss functions provided by the teacher model should adjust dynamically according to the student model's progress, similar to varying difficulty levels in human education. This adaptation is achieved by considering the student model's status when setting the loss functions and adjusting them as the student model develops. This process is visualized in Figure 1. Second, the teacher model is designed to self-improve, mirroring a human teacher's growth through experience. This is accomplished by assuming the loss function to be a neural network, with coefficients determined by a parametric teacher model, also a neural network. The teacher model's parameters are optimized during the teaching process, leading to continuous improvement of the teacher model and the quality of loss functions it produces. We refer to this method as Learning to Teach with Dynamic Loss Functions (L2T-DLF).

3 Methodology

In this section, we overview our L2T-DLN in Section 3.1 , introduce the corresponding framework for student learning in Section 3.2 , describe the DLN learning framework in Section 3.3 , and discuss teacher learning in Section 3.4 .

3.1 Overview

Our L2T-DLN is a differentiable teaching framework that enhances the performance of a student model. The L2T-DLN contains stages: (I) student learning, which optimizes a student model $S_{\theta}$ with parameter $\theta$ ; (II) DLN learning, which optimizes the DLN $L_{\phi}$ with parameter $\phi$ ; (III) teacher learning, which optimizes the teacher model $T_{\varphi}$ with parameter $\varphi$ .

Starting from $S_{\theta}^{0}$ , in stage (I) , we optimize the student model $S_{\theta}^{0}\rightarrow S_{\theta}^{N}$ on training data $x_{train}$ by leveraging the DLN $L_{\phi}^{0}$ as the loss function, where $N$ denotes the number of iterations in a student learning stage. In stage (II) , we compute the error $e_{val}$ of the student model $S_{\theta}^{N}$ on validation data $x_{val}$ , and then determine the gradient $\nabla\phi^{0}=\partial e_{val}/\partial\phi^{0}$ . This gradient is then given to the teacher model, and the DLN is updated as $\phi^{1}=\phi^{0}+g^{0}$ , where $g^{0}$ indicates the output of the teacher model $T_{\varphi}^{0}$ . In stage (III) , we first train the student model $S_{\theta}^{N}\rightarrow S_{\theta}^{2N}$ with the updated DLN $L_{\phi}^{1}$ . Then, we obtain the validation error $e_{val}$ of the student model $S_{\theta}^{2N}$ and optimize the teacher model by backpropagation (BP) based on $e_{val}$ . The objective function of our L2T-DLN is: 
 
 $(\theta^{(M+K)N},\phi^{M},\varphi^{K})\leftarrow(\theta^{0},\phi^{0},\varphi^{0})-\bigtriangledown_{(\theta,\phi,\varphi)}\sum_{k=0}^{K}e_{val}(\theta^{2(k+1)N}).$  (1) 
 Our goal is to achieve $\theta^{(M+K)N}$ , $\phi^{M}$ and $\varphi^{K}$ , where $M$ and $K$ denote the number of iterations of DLN and teacher learning, respectively (details are shown in Figure 2 ).

3.2 Student learning

For a given task, we define the input and output space as $X$ and $Y$ , respectively. The student model is then denoted by $S_{\theta}:X\to Y$ . Our student learning involves minimizing the output value of the DLN, i.e. , $\mathop{\arg\min}\limits_{\theta\in\Omega}{\textstyle\sum_{(x,y)\in x_{train}}wL_{\phi}^{m}(S_{\theta}(x),y)}$ , under a hypothesis space $\Omega$ using training data $x_{train}$ . Note, $w$ is a weight parameter of $x$ , $L_{\phi}^{m}$ is the loss function, and $m$ is the $m^{th}$ iteration for the DLN. During each stage of student learning, we iteratively train the student model $N$ times with $L_{\phi}^{m}$ . The optimization of the student model during the current stage is: 
 
 $\theta^{i}=\theta^{i-1}-\eta\partial wL_{\phi}^{m}(S_{\theta}^{i-1}(x),y)/\partial\theta^{i-1},~{}i=\{1,2,\cdots,N\},$  (2) 
 where $\eta$ denotes the learning rate of the student model. In our framework, the $L_{\phi}^{m}$ that with learnable parameters are optimized in different student learning stages for providing seemly guidance.

3.3 DLN learning

After the student learning stage ( e.g. , $S_{\theta}^{0}\to S_{\theta}^{N}$ with $L_{\phi}^{0}$ ), we use the teacher model $T_{\varphi}^{0}$ to adjust the DLN parameters $\phi$ ( e.g. , $\phi^{0}\to\phi^{1}$ ). To enable the temporal property of DLN, we use an LSTM to transform $\phi$ dynamically: 
 
 $\phi^{1}=\phi^{0}+\gamma g^{0},~{}\begin{bmatrix}g^{0}\\
h^{1}\end{bmatrix}=T_{\varphi}^{0}(\nabla\phi^{0},h^{0}),$  (3) 
 where $\gamma$ denotes the learning rate of DLN and $\nabla\phi^{0}$ represents the gradient of the validation error $e_{val}$ of $S_{\theta}$ with respect to $\phi^{0}$ .

In our approach, Reverse-Mode Differentiation (RMD) [6] is employed to bridge the gap between training data and development data. To provide a clearer understanding of the RMD process, consider it as a unique feed-forward process of a deep neural network, where each 't' represents a layer, and RMD corresponds to the backpropagation process. The gradients are propagated backwards from 'T' to '1'.

Initially, denote 'dθ' as the gradient of $\tilde{M}(f_{\omega_{T}},D_{dev})$ with respect to the teacher model parameters 'θ'. It is set to zero at the start. On the development dataset 'Ddev', the gradient of $\tilde{\mathcal{M}}(f_{\omega},D_{dev})$ with respect to the student model parameter 'ωT' is calculated as follows:

$d\omega_{T}=\frac{\partial\tilde{\mathcal{M}}(f_{\omega_{T}},D_{dev})}{\partial\omega_{T}}=\sum_{(x,y)\in D_{dev}}\frac{\partial\tilde{m}(f_{\omega_{T}}(x),y)}{\partial\omega_{T}}$. (3)

Subsequently, starting from 'T' and following the steps outlined in Eqn. (6), at each step 't={T-1,...,1}', we have:

$d\omega_{t}=\frac{\partial\tilde{\mathcal{M}}(f_{\omega_{t}},D_{dev})}{\partial\omega_{t}}=d\omega_{t+1}-\eta_{t}\frac{\partial^{2}L_{\mu_{\theta}(s_{t})}(f_{\omega_{t}},D_{train}^{t})}{\partial\omega_{t}^{2}}d\omega_{t+1}$. (4)

Simultaneously, the gradient of $\tilde{\mathcal{M}}$ with respect to 'θ' is accumulated at this time step as:

$d\theta=d\theta-\eta_{t}\frac{\partial^{2}L_{\mu_{\theta}(s_{t})}(f_{\omega_{t}},D_{train}^{t})}{\partial\theta\partial\omega_{t}}d\omega_{t+1}$. (5)

The derivations for equations 7 and 5 are deferred to the appendix. It's notable that the computation of the differential terms dt and dtheta involves the hessian vector product, which can be efficiently calculated using the formula $\frac{\partial^{2}g}{\partial x\partial y}v=\frac{\partial}{\partial x}(\frac{\partial g}{\partial y}v)$, without the need to directly compute the Hessian matrix. Moving backwards from t=T to t=1, we derive dt and then update dtheta using any gradient-based optimization algorithm, such as momentum SGD, yielding a single optimization step for dtheta, which we call the teacher optimization step. By repeatedly performing teacher optimization steps, we obtain the final teacher model. The process is outlined in Algorithm 1.

3.4 Teacher learning

In the educational context, the role of a teacher model is to provide the student model with the appropriate coefficients for the loss function at each stage of the learning process. To cater to the varying stages of the student model's training, the teacher model is designed to output distinct loss functions at each training step. The status of the student model at a given timestep is represented by a state vector, containing information such as the current training or development accuracy and the iteration number. The teacher model, denoted as $\mu$, employs this state vector as input to compute the coefficients of the loss function at the current timestep. This computation is represented as $\Phi_{t}=\mu_{\theta}(s_{t})$, where $\theta$ represents the parameters of the teacher model. Further details on $\mu_{\theta}$ are provided in sections 4.1 and 4.2. The loss function for the student model at the current timestep is then $l^{t}=l_{\Phi_{t}}$. The learning process for the student model at the current timestep is expressed as:

 $\omega_{t+1}=\omega_{t}-\eta_{t}\frac{\partial L_{\Phi_{t}}(f_{\omega_{t}},D_{train}^{t})}{\partial\omega_{t}}=\omega_{t}-\eta_{t}\frac{\partial L_{\mu_{\theta}(s_{t})}(f_{\omega_{t}},D_{train}^{t})}{\partial\omega_{t}}$. (1)

This sequential process of obtaining $f_{\omega^{*}}$ (i.e., $f_{\omega_{T}}$ ) constitutes the learning process of the student model, using the training data $D_{train}$ and the loss function supplied by the teacher model $\mu_{\theta}$. To simplify this process, we use the abstract operator $\mathcal{F}$ to denote it: $f_{\omega^{*}}=\mathcal{F}(D_{train},\mu_{\theta})$.

To evaluate the teacher model, we perform another student learning ( e.g. , $S_{\theta}^{N}\to S_{\theta}^{2N}$ ) with the new DLN ( e.g. , $L_{\phi}^{1}$ ). The RMD is also utilized to calculate the gradient of validation error $e_{val}(S_{\theta}^{2N})$ with respect to the teacher model parameters $\varphi^{0}$ . We represent the computation using red lines in Figure 2 . To obtain $\nabla\varphi^{0}$ , we loop the SGD process backward from $2N$ to $N+1$ with the updated DLN $L_{\phi}^{1}$ according to Eq. ( 4 ), ( 5 ) and ( 6 ). At each step $i=\{2N-1,\cdots,N+1\}$ , the gradient $\nabla\varphi^{0}$ is updated as: 
 
 $\nabla\varphi^{0}=\nabla\varphi^{0}-\eta\gamma w\frac{\partial^{3}L_{\phi}^{1}\left(S_{\theta}^{i-1}\left(x_{train}\right),y\right)}{\partial\theta^{i-1}\partial\phi^{1}\partial\varphi^{0}}\nabla\theta^{i}.$  (8) 


The process of L2T-DLN is summarized in Algorithm 1 .

4 Convergence Analysis

Since our L2T-DLN is updated asynchronously, we can only access partial second-order information at each training stage. For example, given a quadratic objective function, while fixing one part of L2T-DLN, the problem is strongly convex with respect to the other part, but the entire problem is nonconvex. Even if the iterates converge for each part to the corresponding minimum points, the stationary point could still be a saddle point for the overall objective function Lu et al. [2018] . Therefore, the analysis of how L2T-DLN exploits the negative curvature is necessary.

The presented research, aligned with the learning to learn and meta learning principles [45], primarily utilizes automated methods to minimize human prior knowledge involvement. Distinguishing from other similar approaches, our work employs gradient-based optimization methods instead of reinforcement learning [60]. Furthermore, we address a technical challenge where error information cannot be directly backpropagated from the loss function, as our goal is to identify the optimal loss function for machine learning models. To resolve this issue, we have developed an algorithm using Reverse-Mode Differentiation (RMD) [7].

In this segment, we delve into the details of the L2T-DLF framework, covering the design of the student and teacher models, as well as the strategies for optimizing the teacher model during training.

Although the higher-order information is divided into two parts, we can still characterize the recursion of the iterates around strict saddle points $v^{*}$ . We can also split $\mathcal{H}$ as two parts, which are 
 
 $\mathcal{H}_{u}=\begin{bmatrix}\bigtriangledown^{2}_{11}e(v^{*})&\bigtriangledown^{2}_{12}e(v^{*})\\
0&\bigtriangledown^{2}_{22}e(v^{*})\end{bmatrix},~{}\mathcal{H}_{l}=\begin{bmatrix}0&0\\
\bigtriangledown^{2}_{21}e(v^{*})&0\end{bmatrix},$  (10) 
 and obviously, we have $\mathcal{H}=\mathcal{H}_{u}+\mathcal{H}_{l}$ .

Then recursion Eq. ( 9 ) can be written as 
 
 $v^{2(k+1)N}+\eta\mathcal{H}_{l}v^{2(k+1)N}=x^{k}-\eta\mathcal{H}_{u}v^{k}-\eta\bigtriangleup^{k}_{u}v^{k}-\eta\bigtriangleup^{k}_{l}v^{2(k+1)N},$  (11) 
 where $\bigtriangleup^{k}_{u}\triangleq\int_{0}^{1}(\mathcal{H}_{u}^{k}(v)-\mathcal{H}_{u})dv$ , $\bigtriangleup^{k}_{l}\triangleq\int_{0}^{1}(\mathcal{H}_{l}^{k}(v)-\mathcal{H}_{l})dv$ . However, it is still unclear from Eq. ( 11 ) how the iteration evolves around the strict saddle point. To highlight ideas, let us define 
 
 $M\triangleq I+\eta\mathcal{H}_{l},~{}G\triangleq I-\eta\mathcal{H}_{u}.$  (12) 
 It can be observed that $M$ is a lower triangular matrix where the diagonal entries are all 1s; therefore it is invertible. After taking the inverse of matrix $M$ on both sides of Eq. ( 11 ), we can obtain 
 
 $v^{k+1}=M^{-1}Gv^{k}-\eta M^{-1}\bigtriangleup^{k}_{u}v^{k}-\eta M^{-1}\bigtriangleup^{k}_{l}v^{2(k+1)N}.$  (13) 
 Our goal of analyzing the recursion of $v^{k}$ becomes to find the maximum eigenvalue of $M^{-1}G$ . With the help of the matrix perturbation theory, we can quantify the difference between the eigenvalues of matrix $\mathcal{H}$ that contains the negative curvature and matrix $M^{-1}G$ that we are interested in analyzing. With the gradient Lipschitz constants $\{\tilde{C}_{k}\}$ , we set $L_{max}\triangleq max\{C_{k},\tilde{C}_{k},\forall k\}\leq C$ and give the following conclusion.

At timestep $t$, the partial derivative of $\omega_{t+1}$ with respect to $\theta$, denoted as $\frac{\partial\omega_{t+1}}{\partial\theta}|_{t}$, signifies the influence of $\theta$ on $\omega_{t+1}$, independent of its impact on $\omega_{t}$. This is depicted by setting $\frac{\partial\omega_{t}}{\partial\theta}=0$ when calculating $\frac{\partial\omega_{t+1}}{\partial\theta}|_{t}$. Furthermore, the final equation in Eqn. (8) utilizes the symmetry of the Hessian matrix.

The proof of Conclusion 1 contains the following steps:

Step 1. (Lemma 1 Lu et al. [2018] ) Giving a generic sequence $u$ generated by AGD ( $v^{k}\in u$ ). As long as the initial point of $u^{k}$ is close to saddle point $\tilde{v}^{k}$ , the distance between $u^{k}$ and $\tilde{v}^{k}$ can be upper bounded by using the $\rho-$ Hessian Lipschitz continuity property.

Step 2. Leveraging the negative curvature around the strict saddle point, we can project the $u^{k}$ onto the two subspaces, where the first subspace is spanned by the eigenvector of $M^{-1}G$ and the other one is spanned by the remaining eigenvectors. We use two steps to show $\lambda_{max}(M^{-1}G)>1$ : 1) we show that all eigenvalues of $Q(\lambda)=[G-\lambda M]$ are real; 2) $\exists\lambda>1,det(Q(\lambda))=0$ .

Conclusion 1 illustrates that there exists a subspace spanned by the eigenvector of $M^{-1}G$ whose eigenvalue is greater than 1, indicating that the sequence generated by AGD can still potentially escape from the strict saddle point by leveraging such negative curvature information (more can be found in supplementary materials).

5 Experiments

Datasets. We evaluate our method on three tasks, i.e. , image classification, objective detection, and semantic segmentation. For the image classification, we use three datasets: CIFAR-10 Krizhevsky [2009] , CIFAR-100 Krizhevsky et al. [2009] , and ImageNet Russakovsky et al. [2015] . CIFAR-10 and CIFAR-100 contain 50000 training and 10000 testing images with 10-class and 100-class separately. ImageNet is a 1000-class task that contains 1281167 training and 50000 testing pairs. For the objective detection, we use MS-COCO dataset Lin et al. [2014] , which contains 82783, 40504, and 81434 pairs in the training, validation, and testing set separately. For the semantic segmentation, we choose PASCAL VOC 2012 Everingham et al. [2010] . Following the procedure of Zhao et al. [2017] , we use augmented data with the annotation of Hariharan et al. [2011] , resulting in 10582, 1449, and 1456 images for training, validation, and testing.

In the realm of practical applications, tailor-made loss functions significantly enhance performance across various tasks. These loss functions either mimic complex, task-specific objectives such as 0-1 accuracy in classification [41], NDCG in ranking [52], BLEU in machine translation [48], and MAP in object detection [22], or facilitate the optimization process of the student model by addressing issues like data imbalance [31] and multiple local optima [20]. The L2T-DLF stands out from previous works due to the following factors: 1) the loss functions are autonomously learned, spanning a broad spectrum without the need for heuristic comprehension of task-specific objectives and optimization processes; 2) the loss function adapts dynamically during training, fostering a more harmonious interplay between the loss and the student model.

Baseline methods. For the classification, we employ several popular loss functions, including fixed loss functions such as Cross Entropy loss (CE), the large-margin softmax loss (L-M softmax) Liu et al. [2016] , and the smooth 0-1 loss function (Smooth) Nguyen and Sanner [2013] as well as dynamic loss functions, namely the adaptive robust loss function (ARLF) Barron [2019] , the L2T-DLF loss function Wu et al. [2018] , stochastic loss function (SLF) Liu and Lai [2020] and ALA Huang et al. [2019] . For objective detection, we compare our approach with the objective function set by YOLO-v3 Redmon and Farhadi [2018] . For the semantic segmentation, we compare our approach with the objective function set by PSPNet Zhao et al. [2017] .

Implementation details. In all experiments, we optimize student models using standard stochastic gradient descent (SGD) with a learning rate of 0.1. The teacher model is trained with Adam, utilizing a learning rate of 0.001. The learning rate of DLN is set to 0.001. The teacher model is trained for 10 epochs, with redividing the training and validation data after each epoch. The validation errors in each task are explicitly reported. Our teacher model comprises a four-layer LSTM Hochreiter and Schmidhuber [1997] with 64 neurons in the first three layers and 1 neuron in the final layer. We utilize a 1-vs-1 approach (details in supplementary materials) to process the student model’s output in both classification and segmentation. We present DLN architecture for each task and ensure reliable evaluation by conducting 5 random restarts, using average results for comprehensive comparisons.

Image classification. For CIFAR-10 and CIFAR 100, we follow the SLF Liu and Lai [2020] and use architectures that include ResNet He et al. [2016] , and Wide-ResNet(WRN) Zagoruyko and Komodakis [2016] as the student model. For ImageNet, we follow the ALA Huang et al. [2019] and use the identical NASNet-A Zoph et al. [2018] . In each experiment, the batch sizes for training and validation are set to 25 and 100, respectively. We perform a five-layer fully connected network, which contains 40 neurons in each hidden layer and 1 neuron in the output layer, as the DLN. The activation function for each hidden layer is set to Leaky-ReLU. The validation error is computed by CE.

Method CIFAR-10 Krizhevsky [2009] CIFAR-100 Krizhevsky et al. [2009] ImageNet Russakovsky et al. [2015] length ResNet8 ResNet20 ResNet32 WRN ResNet8 ResNet20 ResNet32 NASNet-A CE $87.6$ $91.3$ $92.5$ $96.2$ $60.2$ $67.7$ $69.6$ $73.5$ - Smooth Nguyen and Sanner [2013] $87.9$ $91.5$ $92.6$ $96.2$ $60.5$ $68.0$ $69.9$ - - L-M Softmax Liu et al. [2016] $88.7$ $92.0$ $93.0$ $96.3$ $61.1$ $68.4$ $70.4$ - - L2T-DLF Wu et al. [2018] $89.2$ $92.4$ $93.1$ $96.6$ $61.7$ $69.0$ $70.8$ - 1 ARLF Barron [2019] $89.5$ $91.5$ $92.2$ $95.9$ $60.2$ $67.8$ $69.9$ - - SLF Liu and Lai [2020] $89.8$ $93.0$ $93.6$ ${\bf 97.1}$ $62.7$ $69.9$ $71.5$ - - ALA Huang et al. [2019] - - $93.2$ $96.7$ $62.2$ $69.5$ $70.9$ ${\bf 74.6}$ 200 [15] Ours ${\bf 90.7\pm 0.06}$ ${\bf 93.4\pm 0.18}$ ${\bf 93.8\pm 0.20}$ $96.7\pm 0.09$ ${\bf 63.5\pm 0.07}$ ${\bf 70.4\pm 0.03}$ ${\bf 72.0\pm 0.11}$ $74.2$ 25

In the presented findings, the performance of the model on MNIST, CIFAR-10, and CIFAR-100 is demonstrated in Tables 1 and 2. It is evident that the dynamic loss functions produced by the teacher model significantly improve the student model's performance across all tasks. For instance, the teacher model assists in WRN achieving a classification error rate of 3.42% on CIFAR-10, which is comparable to the result obtained through automatic architecture search, such as NASNet's 3.41% error rate. Moreover, our dynamic loss functions for DenseNet on CIFAR-10 reduce the error rate of DenseNet-BC (k = 40) from 3.54% to 3.08%, with a substantial margin of improvement.

Objective detection. In the task of objective detection, the YOLO-v3 model with a backbone of darknet-53 Redmon and Farhadi [2018] is used in this experiment. The traditional loss in the YOLO model is a multi-part loss function, i.e. , $\lambda_{cls}\ell_{cls}+\lambda_{conf}\ell_{conf}+\lambda_{loc}\ell_{loc}$ . $\ell_{cls},\ell_{conf}$ and $\ell_{loc}$ are detailed in supplementary materials. Redmon and Farhadi [2018] set $\lambda_{cls}=\lambda_{conf}=\lambda_{loc}=1$ . In our experiment, our L2T-DLN learns to set these weights dynamically with a single-layer perceptron as DLN. The backbone of the YOLO is pre-trained on ImageNet, and we finetune the header of the YOLO. Specifically, the objective function of the student model is set to $DLN([\ell_{cls},\ell_{conf},\ell_{loc}])$ . The validation error is computed by $\ell_{cls}+\ell_{conf}+\ell_{loc}$ . The batch sizes for training and validation are set to 2 and 8, respectively. The length of student learning is set to 2. We take the training set and 35000 images of the validation set to train our L2T-DLN with an input size of 416*416. From Table 3 , our L2T-DLN has more than $1.6\%$ improvement with the baseline on mAP.

The objective of the teacher model is to produce output that can function as the loss function for the student model, aiming to enhance the long-term performance of the student model. This performance is assessed via task-specific metrics such as 0-1 accuracy in classification and BLEU score in sequence prediction [42], using a separate development dataset. Developing an effective teaching model is complex, as the task-specific metric is often non-smooth with regards to the student model's output, and the final evaluation of the student model occurs on the development set, distinct from the training dataset where the teaching process takes place. We devise an efficient gradient-based optimization algorithm to optimize teacher models. To handle the first challenge, we smooth the task-specific measure to its anticipated version, where the anticipation is taken based on the student model's direct output. To address the second challenge, drawing inspiration from Reverse-Mode Differentiation (RMD) [6], we reverse the stochastic gradient descent training process of the student model, thereby obtaining derivatives of the teacher model's parameters by chaining backwards the error signals incurred on the development dataset.

In our research, we perform extensive empirical validations of the L2T-DLF, a method that identifies optimal loss functions for training student models. Our experimentation encompasses two key domains: image classification and neural machine translation.

In this exposition, the intricate architectural specifics of the student models in the context of neural machine translation, the dataset employed for their training, along with the methodologies utilized for the education of both the student and teacher models, are elucidated.

The length of student learning. The computation of higher-order gradients in L2T-DLN (Eq. ( 6 ) and ( 8 )) is computationally intensive and should be highlighted. Thus, this study explores the influence of the length of student learning ( $N$ ) on the test accuracy and computational load in CIFAR-10 experiments using ResNet8. As shown in Table 5 , the findings reveal that the test accuracy increases with the length of student learning. To make a trade-off between performance and computational cost, we suggest that a maximum length of 25 should be set for student learning. Overall, the study concludes that L2T-DLN has the potential to further improves the performance of student model with sufficient computing resources.

The influence of an LSTM teacher. As introduced above, the teacher model is similar to an optimization algorithm. Then we perform various optimizers, including Adam Kingma and Ba [2014] , SGD, RMSProp Hinton et al. [2012] , and the LSTM teacher, to optimize the DLN and present the results in Table 6 . Compared with ADAM, SGD, and RMSProp, our teacher can improve the performance of the student by $0.48\%$ , $1.6\%$ , and $0.53\%$ . We can conclude that 1) algorithms that can use the historical information, e.g. , momentum, perform well; 2) the adaptability to capture and maintain short- and long-term dependencies can further enhance the loss function teaching, compared to handcrafted methods, e.g. , exponentially weighted moving average Hinton et al. [2012] and moment estimation Kingma and Ba [2014] .

To demonstrate the versatility of L2T-DLF, we selected three popular datasets: MNIST, CIFAR-10, and CIFAR-100. In order to ensure the robustness of our results, we opted for a diverse array of student models. These models encompass a multi-layer perceptron (MLP), a convolutional neural network (CNN) modeled after LeNet architecture [29], and more advanced CNN architectures such as ResNet [21], Wide-ResNet [58], and DenseNet [25]. We utilized momentum stochastic gradient descent for the training of all student models, as detailed in the appendix, which provides an overview of the network structures of the chosen models.

5.1 Experimental setup

In our approach, we employ the sophisticated convolutional neural network (CNN) architecture, ResNet [21], for CIFAR-10 and CIFAR-100, varying the number of layers. Additionally, we incorporate the high-performing Wide-ResNet [58] and DenseNet [25] architectures.

Evaluation metrics. In the classification, we use the accuracy on the testing set of each dataset Wu et al. [2018] . In the objective detection, we use the mean of Average Precision (mAP) Redmon and Farhadi [2018] to evaluate the student model on the testing set of MS-COCO Lin et al. [2014] . In the semantic segmentation, we use Mean Intersection over Union (mIoU) Zhao et al. [2017] to evaluate the student model on the testing set of VOC Everingham et al. [2010] .

Baseline methods. For the classification, we employ several popular loss functions, including fixed loss functions such as Cross Entropy loss (CE), the large-margin softmax loss (L-M softmax) Liu et al. [2016] , and the smooth 0-1 loss function (Smooth) Nguyen and Sanner [2013] as well as dynamic loss functions, namely the adaptive robust loss function (ARLF) Barron [2019] , the L2T-DLF loss function Wu et al. [2018] , stochastic loss function (SLF) Liu and Lai [2020] and ALA Huang et al. [2019] . For objective detection, we compare our approach with the objective function set by YOLO-v3 Redmon and Farhadi [2018] . For the semantic segmentation, we compare our approach with the objective function set by PSPNet Zhao et al. [2017] .

Implementation details. In all experiments, we optimize student models using standard stochastic gradient descent (SGD) with a learning rate of 0.1. The teacher model is trained with Adam, utilizing a learning rate of 0.001. The learning rate of DLN is set to 0.001. The teacher model is trained for 10 epochs, with redividing the training and validation data after each epoch. The validation errors in each task are explicitly reported. Our teacher model comprises a four-layer LSTM Hochreiter and Schmidhuber [1997] with 64 neurons in the first three layers and 1 neuron in the final layer. We utilize a 1-vs-1 approach (details in supplementary materials) to process the student model’s output in both classification and segmentation. We present DLN architecture for each task and ensure reliable evaluation by conducting 5 random restarts, using average results for comprehensive comparisons.

5.2 Results

Image classification. For CIFAR-10 and CIFAR 100, we follow the SLF Liu and Lai [2020] and use architectures that include ResNet He et al. [2016] , and Wide-ResNet(WRN) Zagoruyko and Komodakis [2016] as the student model. For ImageNet, we follow the ALA Huang et al. [2019] and use the identical NASNet-A Zoph et al. [2018] . In each experiment, the batch sizes for training and validation are set to 25 and 100, respectively. We perform a five-layer fully connected network, which contains 40 neurons in each hidden layer and 1 neuron in the output layer, as the DLN. The activation function for each hidden layer is set to Leaky-ReLU. The validation error is computed by CE.

Table 1 reports the performance of each loss function. Our approach achieves the best results on CIFAR-10 with ResNet8, ResNet20, and ResNet32, achieving $90.70\%,93.40\%$ , and $93.81\%$ , respectively. On CIFAR-100, our method also outperforms baselines with an overall accuracy of $63.50\%,70.47\%$ , and $72.06\%$ for ResNet8, ResNet20, and ResNet32, respectively. For WRN, our approach achieves the second-best performance, following the SLF method. The results on ImageNet illustrate that L2T-DLN improves the accuracy of the baseline by $0.7\%$ . On ImageNet, our DLN demonstrates the second-best performance. The performance of ALA benefits from the larger length of a student learning stage ALA set (200) compared with ours (25). The ablation showed that the size of the length is positively correlated with the test accuracy and computational consumption (see Table 5 ).

Objective detection. In the task of objective detection, the YOLO-v3 model with a backbone of darknet-53 Redmon and Farhadi [2018] is used in this experiment. The traditional loss in the YOLO model is a multi-part loss function, i.e. , $\lambda_{cls}\ell_{cls}+\lambda_{conf}\ell_{conf}+\lambda_{loc}\ell_{loc}$ . $\ell_{cls},\ell_{conf}$ and $\ell_{loc}$ are detailed in supplementary materials. Redmon and Farhadi [2018] set $\lambda_{cls}=\lambda_{conf}=\lambda_{loc}=1$ . In our experiment, our L2T-DLN learns to set these weights dynamically with a single-layer perceptron as DLN. The backbone of the YOLO is pre-trained on ImageNet, and we finetune the header of the YOLO. Specifically, the objective function of the student model is set to $DLN([\ell_{cls},\ell_{conf},\ell_{loc}])$ . The validation error is computed by $\ell_{cls}+\ell_{conf}+\ell_{loc}$ . The batch sizes for training and validation are set to 2 and 8, respectively. The length of student learning is set to 2. We take the training set and 35000 images of the validation set to train our L2T-DLN with an input size of 416*416. From Table 3 , our L2T-DLN has more than $1.6\%$ improvement with the baseline on mAP.

Semantic segmentation. The objective function of PSPNet Zhao et al. [2017] is set to $CE(p,y)+0.4*CE(aux_{p},y)$ , where $p$ , $aux_{p}$ , and $y$ denote the output of the master branch, the auxiliary branch of PSPNet, and the ground truth, respectively. For PSPNet with L2T-DLN, the objective function is set to $DLN(p,y)+0.4*DLN(aux_{p},y)$ , where the architecture of DLN is the one used in classification tasks. The validation error is computed by $CE(p,y)+0.4*CE(aux_{p},y)$ . The batch sizes for training and validation are set to 2 and 8, respectively. The length of student learning is set to 2. Table 3 shows that our L2T-DLN improves $0.3\%$ compared with the baseline on mIoU.

5.3 Ablations

In this subsection, we conduct ablation studies on CIFAR-10 Krizhevsky [2009] using ResNet8 to analyze the L2T-DLN synthetically. We specifically examine the proportion of training and validation data, the length of student learning stage ( $N$ ), the wrong learning rate setting, and the influence of the LSTM teacher. Furthermore, we provide the visualization of DLN at different learning stages in MNIST and CIFAR10 tasks. We assess the impact of each component by computing the test accuracy of the student model after optimizing the teacher model for 10 epochs.

The proportion of training and validation data. In L2T-DLN, the training dataset is divided into two sets: validation data and training data, with validation data serving as an unbiased estimator for model generalization. After each epoch, the dataset is redivided, allowing samples used in the validation data to be included in the training data, and vice versa. The validation ratio represents the fraction of training dataset samples exclusively used for validation. This study explores different training-validation data separations. Table 4 results indicate our performance remains stable across varying ratios due to the teacher’s ability to capture short- and long-term dependencies. To make a trade-off between computational cost and accuracy, we set the ratio $=50\%$ for all our experiments.

The length of student learning. The computation of higher-order gradients in L2T-DLN (Eq. ( 6 ) and ( 8 )) is computationally intensive and should be highlighted. Thus, this study explores the influence of the length of student learning ( $N$ ) on the test accuracy and computational load in CIFAR-10 experiments using ResNet8. As shown in Table 5 , the findings reveal that the test accuracy increases with the length of student learning. To make a trade-off between performance and computational cost, we suggest that a maximum length of 25 should be set for student learning. Overall, the study concludes that L2T-DLN has the potential to further improves the performance of student model with sufficient computing resources.

The influence of an LSTM teacher. As introduced above, the teacher model is similar to an optimization algorithm. Then we perform various optimizers, including Adam Kingma and Ba [2014] , SGD, RMSProp Hinton et al. [2012] , and the LSTM teacher, to optimize the DLN and present the results in Table 6 . Compared with ADAM, SGD, and RMSProp, our teacher can improve the performance of the student by $0.48\%$ , $1.6\%$ , and $0.53\%$ . We can conclude that 1) algorithms that can use the historical information, e.g. , momentum, perform well; 2) the adaptability to capture and maintain short- and long-term dependencies can further enhance the loss function teaching, compared to handcrafted methods, e.g. , exponentially weighted moving average Hinton et al. [2012] and moment estimation Kingma and Ba [2014] .

Visualization. We visualize the loss value of DLN on MNIST and CIFAR-10 separately in Figure 3 , which illustrates the capacity of L2T-DLN to adapt to the evolving states of students to attain improved performance. The DLN is initialized with the Kaiming normal initialization with LeakyReLU activations.

6 Conclusions

This paper introduces L2T-DLN, an adaptive model for various stages of student learning. Technically, We propose a differentiable three-stage teaching framework, asynchronously optimizing the student, DLN, and teacher. An LSTM teacher dynamically captures and retains experiences during DLN learning. Additionally, we assess L2T-DLN’s ability to navigate strict saddle points using the negative curvature of their Hessian matrix. Experiments demonstrate our DLN outperforming specially designed loss functions. Nevertheless, our approach demands significant computational resources for high-order derivatives, which we aim to mitigate in future work.

7 Acknowledgment

The research project was funded by three sources:
1. National Natural Science Foundation of China (grant numbers 62302045 and 82171965)
2. Clinical and Translational Medical Research Fund of the Chinese Academy of Medical Sciences (grant number 2020-I2M-C&T-B-072)
3. Beijing Institute of Technology Research Fund Program for Young Scholars.

References

Andrychowicz et al. [2016] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient descent. Advances in neural information processing systems, 29, 2016.
Baik et al. [2021] Sungyong Baik, Janghoon Choi, Heewon Kim, Dohee Cho, Jaesik Min, and Kyoung Mu Lee. Meta-learning with task-adaptive loss function for few-shot learning. InProceedings of the IEEE/CVF International Conference on Computer Vision, pages 9465–9474, 2021.
Barron [2019] Jonathan T Barron. A general and adaptive robust loss function. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4331–4339, 2019.
Bertsekas [1997] Dimitri P Bertsekas. Nonlinear programming. Journal of the Operational Research Society, 48(3):334–334, 1997.
Bradford [1958] Leland P Bradford. The teaching-learning transaction. Adult Education, 8(3):135–145, 1958.
Everingham et al. [2010] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88:303–338, 2010.
Fan et al. [2018] Yang Fan, Fei Tian, Tao Qin, Xiang-Yang Li, and Tie-Yan Liu. Learning to teach. InInternational Conference on Learning Representations, 2018.
Fan et al. [2021] Yang Fan, Yingce Xia, Lijun Wu, Shufang Xie, Weiqing Liu, Jiang Bian, Tao Qin, and Xiang-Yang Li. Learning to reweight with deep interactions. InProceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 7385–7393, 2021.
Gers et al. [2000] Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. Learning to forget: Continual prediction with lstm. Neural computation, 12(10):2451–2471, 2000.
Han et al. [2023] Mengqiao Han, Liyuan Pan, and Xiabi Liu. Astronet: When astrocyte meets artificial neural network. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 20258–20268, June 2023.
Hariharan et al. [2011] Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. Semantic contours from inverse detectors. In2011 international conference on computer vision, pages 991–998. IEEE, 2011.
He et al. [2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.
Hinton et al. [2012] Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. Neural networks for machine learning lecture 6a overview of mini-batch gradient descent. Cited on, 14(8):2, 2012.
Hochreiter and Schmidhuber [1997] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.
[15] Chen Huang, Shuangfei Zhai, Walter Talbott, Miguel Angel Bautista, Shih-Yu Sun, Carlos Guestrin, and Josh Susskind. Addressing the loss-metric mismatch with adaptive loss alignment supplementary material.
Huang et al. [2019] Chen Huang, Shuangfei Zhai, Walter Talbott, Miguel Bautista Martin, Shih-Yu Sun, Carlos Guestrin, and Josh Susskind. Addressing the loss-metric mismatch with adaptive loss alignment. InInternational conference on machine learning, pages 2891–2900. PMLR, 2019.
Ihejirika [2013] JC Ihejirika. Teaching strategies for adult learners: Implications of learning characteristics for effective teaching-learning transaction. Academic Research International, 4(2):310, 2013.
Jiang et al. [2018] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. InInternational conference on machine learning, pages 2304–2313. PMLR, 2018.
Kingma and Ba [2014] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
Krizhevsky [2009] A Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis, University of Tront, 2009.
Krizhevsky et al. [2009] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 and cifar-100 datasets. URl: https://www. cs. toronto. edu/kriz/cifar. html, 6(1):1, 2009.
Lin et al. [2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft coco: Common objects in context. InComputer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740–755. Springer, 2014.
Liu and Lai [2020] Qingliang Liu and Jinmei Lai. Stochastic loss function. InProceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 4884–4891, 2020.
Liu et al. [2016] Weiyang Liu, Yandong Wen, Zhiding Yu, and Meng Yang. Large-margin softmax loss for convolutional neural networks. InInternational Conference on Machine Learning, pages 507–516. PMLR, 2016.
Liu et al. [2017] Weiyang Liu, Bo Dai, Ahmad Humayun, Charlene Tay, Chen Yu, Linda B Smith, James M Rehg, and Le Song. Iterative machine teaching. InInternational Conference on Machine Learning, pages 2149–2158. PMLR, 2017.
Lu et al. [2018] Songtao Lu, Mingyi Hong, and Zhengdao Wang. On the sublinear convergence of randomly perturbed alternating gradient descent to second order stationary solutions. arXiv preprint arXiv:1802.10418, 2018.
Mehra and Mital [2007] Payal Mehra and Monika Mital. Integrating technology into the teaching-learning transaction: Pedagogical and technological perceptions of management faculty. International Journal of Education and Development using ICT, 3(1), 2007.
Morris [2018] Thomas Howard Morris. Vocational education of young adults in england: A systemic analysis of teaching–learning transactions that facilitate self-directed learning. Journal of Vocational Education & Training, 70(4):619–643, 2018.
Ngussa and Makewa [2014] Baraka Manjale Ngussa and Lazarus Ndiku Makewa. Constructivism experiences in teaching-learning transaction among adventist secondary schools in south nyanza, tanzania. American Journal of Educational Research, 2(11A):1–7, 2014.
Nguyen and Sanner [2013] Tan Nguyen and Scott Sanner. Algorithms for direct 0–1 loss optimization in binary classification. InInternational Conference on Machine Learning, pages 1085–1093. PMLR, 2013.
Redmon and Farhadi [2018] Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767, 2018.
Ren et al. [2018] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning. InInternational conference on machine learning, pages 4334–4343. PMLR, 2018.
Russakovsky et al. [2015] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115:211–252, 2015.
Schmidhuber [1987] Jürgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-… hook. PhD thesis, Technische Universität München, 1987.
Shu et al. [2019] Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng. Meta-weight-net: Learning an explicit mapping for sample weighting. Advances in neural information processing systems, 32, 2019.
Thrun and Pratt [2012] Sebastian Thrun and Lorien Pratt. Learning to learn. Springer Science & Business Media, 2012.
Wu et al. [2018] Lijun Wu, Fei Tian, Yingce Xia, Yang Fan, Tao Qin, Lai Jian-Huang, and Tie-Yan Liu. Learning to teach with dynamic loss functions. Advances in neural information processing systems, 31, 2018.
Yang et al. [2023] Yan Yang, Liyuan Pan, and Liu Liu. Event camera data pre-training. InProceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 10699–10709, October 2023.
Zagoruyko and Komodakis [2016] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. InBritish Machine Vision Conference 2016. British Machine Vision Association, 2016.
Zhao et al. [2017] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision and pattern recognition, pages 2881–2890, 2017.
Zhu [2015] Xiaojin Zhu. Machine teaching: An inverse problem to machine learning and an approach toward optimal education. InProceedings of the AAAI Conference on Artificial Intelligence, volume 29, 2015.
Zoph and Le [2016] Barret Zoph and Quoc Le. Neural architecture search with reinforcement learning. InInternational Conference on Learning Representations, 2016.
Zoph et al. [2018] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition, pages 8697–8710, 2018.
